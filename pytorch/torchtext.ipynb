{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Torchtext Tutorial\n",
    "- 기능:\n",
    "    - 파일 로드\n",
    "    - 토크나이징\n",
    "    - 단어 집합(Vocab)\n",
    "    - 정수 인코딩(Integer encoding): 전체 코퍼스의 단어들 각각 고유한 정수로 맵핑\n",
    "    - 단어 벡터(Word Vector): 단어 집합의 단어들에 고유한 임베딩 벡터를 만들어 준다. 랜덤값으로 초기화 한 값일수도 있고, 사전 훈련된 임베딩 벡터를 로드할 수도 있다.\n",
    "    - 배치화: 훈련 샘플들의 배치 만들어 줌. 이 과정에서 패딩도 이뤄진다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 데이터 불러오기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "import urllib.request\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = pd.read_csv('./data/train.csv')\n",
    "test_df = pd.read_csv('./data/test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# country 컬럼을 선택합니다.\n",
    "# 컬럼의 값과 조건을 비교합니다.\n",
    "# 그 결과를 새로운 변수에 할당합니다.\n",
    "is_venezuela = train_df['country'] == 'Venezuela'\n",
    "\n",
    "# 조건를 충족하는 데이터를 필터링하여 새로운 변수에 저장합니다.\n",
    "venezuela = df[is_venezuela]\n",
    "\n",
    "# 결과를 출력합니다.\n",
    "venezuela"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 필드 정의하기(torchtext.data)\n",
    "- sequential: 시퀀스 데이터 여부\n",
    "- use_vocab: 단어 집합 만들 것인지 여부\n",
    "- tokenize: 어떤 토큰화 함수 사용할 것인지 지정\n",
    "- lower: 소문자화\n",
    "- batch_first: 미니 배치 차원을 맨 앞으로 해 데이터 불러올 것인지 여부\n",
    "- is_target: 레이블 데이터 여부\n",
    "- fix_length: 최대 허용 길이. 이 길이에 패딩 진행"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchtext.legacy import data\n",
    "\n",
    "# 필드 정의\n",
    "TEXT = data.Field(sequential=True,\n",
    "                  use_vocab=True,\n",
    "                  tokenize=str.split,\n",
    "                  lower=True,\n",
    "                  batch_first=True,\n",
    "                  fix_length=300)\n",
    "\n",
    "LABEL = data.Field(sequential=False,\n",
    "                   use_vocab=False,\n",
    "                   batch_first=False,\n",
    "                   is_target=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 데이터셋 만들기\n",
    "- TabularDataset: 데이터 불러오면서 필드에서 정의했던 토큰화 방법으로 토큰화 수행"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchtext.legacy.data import TabularDataset\n",
    "\n",
    "train_data, test_data = TabularDataset.splits(path='.', train='./data/train.csv', test='./data/test.csv', format='csv',\n",
    "                                             fields=[('text', TEXT), ('label', LABEL)], skip_header=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training: 25000\n",
      "test: 25000\n"
     ]
    }
   ],
   "source": [
    "print('training: {}'.format(len(train_data)))\n",
    "print('test: {}'.format(len(test_data)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'text': ['for', 'a', 'movie', 'that', 'gets', 'no', 'respect', 'there', 'sure', 'are', 'a', 'lot', 'of', 'memorable', 'quotes', 'listed', 'for', 'this', 'gem.', 'imagine', 'a', 'movie', 'where', 'joe', 'piscopo', 'is', 'actually', 'funny!', 'maureen', 'stapleton', 'is', 'a', 'scene', 'stealer.', 'the', 'moroni', 'character', 'is', 'an', 'absolute', 'scream.', 'watch', 'for', 'alan', '\"the', 'skipper\"', 'hale', 'jr.', 'as', 'a', 'police', 'sgt.'], 'label': '0'}\n"
     ]
    }
   ],
   "source": [
    "# 주어진 인덱스의 샘플 확인 가능\n",
    "print(vars(train_data[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_items([('text', <torchtext.legacy.data.field.Field object at 0x160c9bb90>), ('label', <torchtext.legacy.data.field.Field object at 0x160c9bb50>)])\n"
     ]
    }
   ],
   "source": [
    "# 필드 구성 확인\n",
    "print(train_data.fields.items())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 단어 집합(Vocabulary) 만들기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "단어 집합의 크기 : 10002\n"
     ]
    }
   ],
   "source": [
    "TEXT.build_vocab(train_data, min_freq=10, max_size=10000)\n",
    "print('단어 집합의 크기 : {}'.format(len(TEXT.vocab)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "defaultdict(<bound method Vocab._default_unk_index of <torchtext.vocab.Vocab object at 0x189b81ed0>>, {'<unk>': 0, '0': 1, '1': 2})\n"
     ]
    }
   ],
   "source": [
    "LABEL.build_vocab(train_data)\n",
    "print(LABEL.vocab.stoi)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## torchtext의 데이터로더 만들기\n",
    "- 데이터로더는 데이터셋에서 미니배치만큼 데이터 로드하게 만들어 주는 역할\n",
    "    - torchtext에서는 iterator 사용해 데이터로더를 만든다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchtext.legacy.data import Iterator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 5\n",
    "\n",
    "train_loader = Iterator(dataset=train_data, batch_size=batch_size)\n",
    "test_loader = Iterator(dataset=test_data, batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "훈련 데이터의 미니 배치 수 : 5000\n",
      "테스트 데이터의 미니 배치 수 : 5000\n"
     ]
    }
   ],
   "source": [
    "# 25,000개의 샘플을 배치 크기 5개씩 묶어주었기 때문\n",
    "print('훈련 데이터의 미니 배치 수 : {}'.format(len(train_loader)))\n",
    "print('테스트 데이터의 미니 배치 수 : {}'.format(len(test_loader)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 첫번째 미니배치 가져와서 batch라는 변수에 저장해보자\n",
    "batch = next(iter(train_loader))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([  10,   20,    7,    3, 2274,   77,   12, 1113,   17,    0,   18, 6660,\n",
      "           0,   13,  165,    0,  935,   11,  281,   12,    7, 6285,   15,    3,\n",
      "        4693, 3052, 1131,    4, 8079, 9739,    7, 1001,   12, 1113,   29,    3,\n",
      "           0,    0,  266,    0, 6236,   44,   23,   43, 9496,  580,    0,   40,\n",
      "        1588,    0,   25,  207,   28, 3980,    4, 1610, 1269,    2, 1719,  629,\n",
      "          44,    0,   77,  189,   48,    2,  258,  122,  699,    2,  548,   41,\n",
      "           6,  110,  101,    4,   98,   15,   10,   75,    0,   13,  165,   74,\n",
      "          23,  184,    0,   77,   11, 6294,    2,  249,    5, 2152,    2,  131,\n",
      "           7,   48,  788,  308,   34,    2,   80,    0,   32,  952,    0, 2026,\n",
      "        3160,  689,    4, 6923, 4604,   19,   16,    3, 4693, 3052, 1764,   39,\n",
      "         135, 1415,    4, 4869, 2244,    4,    0, 1052,    0,  108,   13,    0,\n",
      "          12,   34, 3587,   13,  255,   20,  458,   29,    3, 2922,    0,   17,\n",
      "           3, 1166,    0,    5, 4693,    0,   11,    0,  515,   17,    0, 5090,\n",
      "        6707,    0,   13, 2549,   12,  763,    6,    0,   13,   93,  132,   19,\n",
      "          35,  575,    7,    0,    4,  669,   45,    5,    2, 1458,   22, 9273,\n",
      "         831,   18,   33,   35,    0,    4,   33,    0,    4,    2,  800, 5074,\n",
      "           0,    8,    2, 1166,    7,   39,  439,   15,    2,    0, 2582, 1562,\n",
      "        3148,    0,   35,    7,   23,  245,   29,    2,    0,   13,  737,   29,\n",
      "           2,    0,   35,    7,   23,   48,   12,    0,   13,    0, 4350,    4,\n",
      "         453,    2, 3334,  214,    6,  110,   10,    0,    4,  453,   65,    2,\n",
      "           0,   10,   20,  438,   25,    6,    0,    1,    1,    1,    1,    1,\n",
      "           1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n",
      "           1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n",
      "           1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n",
      "           1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1])\n"
     ]
    }
   ],
   "source": [
    "print(batch.text[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <pad> 토큰이 사용되는 경우"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'Field' object has no attribute 'vocab'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-69-d25074f1dbb2>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mLABEL\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvocab\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m: 'Field' object has no attribute 'vocab'"
     ]
    }
   ],
   "source": [
    "len(LABEL.vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
